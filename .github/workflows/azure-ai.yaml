name: Azure ML Job Pipeline

on:
  workflow_dispatch:
    inputs:
      create_compute:
        description: 'Create compute'
        required: false
        default: true
      train_model:
        description: 'Train model'
        required: false
        default: true
      skip_training_pipeline:
        description: 'Skip training pipeline'
        required: false
        default: true
      deploy_model:
        description: 'Deploy the AI model onto local Kubernetes cluster'
        required: false
        default: true
    branches:
      - main
  push:
    branches:
      - main

env:
  GROUP: mlops
  WORKSPACE: mlops-nathan
  LOCATION: westeurope
  # Allow to override for each run, in the workflow dispatch manual starts
  CREATE_COMPUTE: ${{ github.event.inputs.create_compute }}
  TRAIN_MODEL: ${{ github.event.inputs.train_model }}
  SKIP_TRAINING_PIPELINE: ${{ github.event.inputs.skip_training_pipeline }}
  DEPLOY_MODEL: ${{ github.event.inputs.deploy_model }}

jobs:
  azure-pipeline:
    if: ${{ inputs.skip_training_pipeline }}
    runs-on: ubuntu-latest
    # runs-on: self-hosted
    steps:
    - name: Check out repository
      uses: actions/checkout@v4
      
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    # AZURE_CREDENTIALS should be a secret in your repo containing a JSON string of your service principal details

    - name: Create compute
      uses: azure/CLI@v1
      id: prepare-ml-pipeline
      if: ${{ env.CREATE_COMPUTE == 'true' }}
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml compute create --file ./environment/compute.yaml

    - name: Start compute
      uses: azure/CLI@v1
      # If the previous step was executed and succeeded or skipped
      if: ${{ steps.prepare-ml-pipeline.outcome == 'success' }} || ${{ steps.prepare-ml-pipeline.outcome == 'skipped' }} 
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml compute start --name cli-created-machine
      continue-on-error: true
    
    - name: Execute Azure ML Script
      uses: azure/CLI@v1
      id: azure-ml-pipeline
      if: ${{ env.TRAIN_MODEL == 'true' }}
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml job create --file ./pipelines/animals-classification.yaml --set name=animals-classification-${{ github.sha }}-${{ github.run_id }} --stream
          VERSION=$(az ml model list -n animal-classification --query "[0].version" -o tsv)
          echo "Latest version of model animal-classification is: $VERSION"
          echo "::set-output name=latest_version::$VERSION"

    - name: Cleanup Compute
      uses: azure/CLI@v1
      if: always()
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml compute stop --name cli-created-machine
      continue-on-error: true

  download:
    needs: azure-pipeline
    # Only run if azure-pipeline is succeeded OR skipped
    if: ${{ needs.azure-pipeline.result == 'success' || needs.azure-pipeline.result == 'skipped' }}
    # runs-on: self-hosted
    runs-on: ubuntu-latest
    steps:
    - name: Check out repository
      uses: actions/checkout@v4
      
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Download model
      uses: azure/CLI@v1
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml model download --name animal-classification --download-path ./inference --version ${{ steps.azure-ml-pipeline.outputs.latest_version }}"
    
    # - name: Move model
    #   run: |
    #     ls inference/animal-classification/animals-classification/INPUT_model_path
    #     mv inference/animal-classification/animals-classification/INPUT_model_path/animal-cnn inference
 
    - name: Upload API Code for Docker
      # if: inputs.local_deployment
      uses: actions/upload-artifact@v2
      with:
        name: docker-config
        path: inference

  deploy:
    needs: download
    # Only run if download is succeeded OR skipped AND if the deploy_model variable is true
    if: ${{
      (
        needs.download.result == 'success' ||
        needs.download.result == 'skipped'
      ) &&
      inputs.deploy_model }}
    runs-on: self-hosted
    # runs-on: ubuntu-latest
    steps:
    - name: Gather Docker Meta Information
      id: docker-meta-data
      uses: docker/metadata-action@v3
      with:
        # list of Docker images to use as base name for tags
        # Use this for Docker Hub
        # nathansegers/mlops-animals-api
        images: |
          ghcr.io/nathansegers/mlops-animals-api
        # generate Docker tags based on the following events/attributes:
        # The GitHub Branch
        # The GitHub SHA
        # More info: https://github.com/docker/build-push-action/blob/master/docs/advanced/tags-labels.md
        tags: |
          type=ref,event=branch
          type=sha
    
    # Enter your GITHUB Token here!
    - name: Login to GHCR
      uses: docker/login-action@v1
      with:
        registry: ghcr.io
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GITHUB_TOKEN }}

    # # Enter your DOCKER HUB Token here!
    # - name: Login to Docker Hub
    #   uses: docker/login-action@v1
    #   with:
    #     username: ${{ github.repository_owner }}
    #     password: ${{ secrets.DOCKER_HUB_PASSWORD }}

    # Download artifact from previous step
    - name: Download API Code for Docker
      uses: actions/download-artifact@v2
      with:
        name: docker-config
        path: inference

    - name: Docker Build and push
      id: docker_build
      uses: docker/build-push-action@v2
      with:
        context: ./inference
        push: true
        tags: ${{ steps.docker-meta-data.outputs.tags }}