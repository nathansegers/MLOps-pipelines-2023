name: Azure ML Job Pipeline

on:
  workflow_dispatch:
    inputs:
      create_compute:
        description: 'Create compute'
        required: false
        default: true
        type: boolean
      train_model:
        description: 'Train model'
        required: false
        default: false
        type: boolean
      skip_training_pipeline:
        description: 'Skip training pipeline'
        required: false
        default: true
        type: boolean
      deploy_model:
        description: 'Deploy the AI model onto local Kubernetes cluster'
        required: false
        default: false
        type: boolean
      # compute_name:
      #   type: string
      #   description: "The name of the compute to start or stop"
      #   required: true
      #   default: cli-created-machine
    branches:
      - main
  workflow_call:
    inputs:
      create_compute:
        description: 'Create compute'
        required: false
        default: true
        type: boolean
      train_model:
        description: 'Train model'
        required: false
        default: false
        type: boolean
      skip_training_pipeline:
        description: 'Skip training pipeline'
        required: false
        default: true
        type: boolean
      deploy_model:
        description: 'Deploy the AI model onto local Kubernetes cluster'
        required: false
        default: false
        type: boolean


env:
  GROUP: mlops
  WORKSPACE: mlops-nathan
  LOCATION: westeurope
  # Allow to override for each run, in the workflow dispatch manual starts
  CREATE_COMPUTE: ${{ github.event.inputs.create_compute }}
  TRAIN_MODEL: ${{ github.event.inputs.train_model }}
  SKIP_TRAINING_PIPELINE: ${{ github.event.inputs.skip_training_pipeline }}
  DEPLOY_MODEL: ${{ github.event.inputs.deploy_model }}

jobs:
  azure-pipeline:
    if: ${{ inputs.skip_training_pipeline }}
    runs-on: ubuntu-latest
    # runs-on: self-hosted
    outputs:
      ai-model-version: ${{ steps.azure-ml-pipeline.outputs.latest_version }}
    steps:
    - name: Check out repository
      uses: actions/checkout@v4
      
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    # AZURE_CREDENTIALS should be a secret in your repo containing a JSON string of your service principal details

    - name: Install YQ
      uses: dcarbone/install-yq-action@v1.1.1      

    - name: read-yaml-file
      id: read_compute_yaml
      run:
        echo "name=$(yq ".name" ./environment/compute.yaml)" >> $GITHUB_OUTPUT

    - name: Create compute
      uses: azure/CLI@v1
      id: prepare-ml-pipeline
      if: ${{ inputs.create_compute }}
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml compute create --file ./environment/compute.yaml

    - name: Start compute
      uses: azure/CLI@v1
      # If the previous step was executed and succeeded or skipped
      if: ${{ steps.prepare-ml-pipeline.outcome == 'success'  || steps.prepare-ml-pipeline.outcome == 'skipped' }} 
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml compute start --name "$name"
          echo "$name"
      continue-on-error: true
    
    - name: Execute Azure ML Script
      uses: azure/CLI@v1
      id: azure-ml-pipeline
      if: ${{ inputs.train_model }}
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml job create --file ./pipelines/animals-classification.yaml --set name=animals-classification-${{ github.sha }}-${{ github.run_id }} --stream

    - name: Cleanup Compute
      uses: azure/CLI@v1
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          az ml compute stop --name ${{ steps.read_compute_yaml.outputs.name }}
      continue-on-error: true

  download:
    needs: azure-pipeline
    # Only run if azure-pipeline is succeeded OR skipped
    if: ${{ needs.azure-pipeline.result == 'success' || needs.azure-pipeline.result == 'skipped' }}
    # runs-on: self-hosted
    runs-on: ubuntu-latest
    steps:

    - name: Check out repository
      uses: actions/checkout@v4
      
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Set model version
      uses: azure/CLI@v1
      with:
        azcliversion: 2.53.0
        inlineScript: |
          az extension add --name ml -y
          az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
          VERSION=$(az ml model list -n animal-classification --query "[0].version" -o tsv)
          az ml model download --name animal-classification --download-path ./inference --version $VERSION"
    
    - name: Upload API Code for Docker
      # if: inputs.local_deployment
      uses: actions/upload-artifact@v2
      with:
        name: docker-config
        path: inference

  deploy:
    needs: download
    # Only run if download is succeeded OR skipped AND if the deploy_model variable is true
    if: ${{
      (
        needs.download.result == 'success' ||
        needs.download.result == 'skipped'
      ) &&
      inputs.deploy_model }}
    runs-on: self-hosted
    # runs-on: ubuntu-latest
    steps:
    - name: Gather Docker Meta Information
      id: docker-meta-data
      uses: docker/metadata-action@v3
      with:
        # list of Docker images to use as base name for tags
        # Use this for Docker Hub
        # nathansegers/mlops-animals-api
        images: |
          ghcr.io/nathansegers/mlops-animals-api
        # generate Docker tags based on the following events/attributes:
        # The GitHub Branch
        # The GitHub SHA
        # More info: https://github.com/docker/build-push-action/blob/master/docs/advanced/tags-labels.md
        tags: |
          type=ref,event=branch
          type=sha
    
    # Enter your GITHUB Token here!
    - name: Login to GHCR
      uses: docker/login-action@v1
      with:
        registry: ghcr.io
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GITHUB_TOKEN }}

    # # Enter your DOCKER HUB Token here!
    # - name: Login to Docker Hub
    #   uses: docker/login-action@v1
    #   with:
    #     username: ${{ github.repository_owner }}
    #     password: ${{ secrets.DOCKER_HUB_PASSWORD }}

    # Download artifact from previous step
    - name: Download API Code for Docker
      uses: actions/download-artifact@v2
      with:
        name: docker-config
        path: inference

    - name: Docker Build and push
      id: docker_build
      uses: docker/build-push-action@v2
      with:
        context: ./inference
        push: true
        tags: ${{ steps.docker-meta-data.outputs.tags }}