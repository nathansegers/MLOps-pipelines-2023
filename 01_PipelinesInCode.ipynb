{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, you will need to create an environment to run these cells. I have done so using a \"pyenv\", follow the instructions on the internet to do so.\n",
        "This allows me to simply install the necessary packages and then run this notebook file using the right kernel (selected here in the top right corner: \"mlops (Python 3.10.10)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1683701622980
        }
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import load_component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "## Either get environment variables, or a fallback name, which is the second parameter.\n",
        "## Currently, fill in the fallback values. Later on, we will make sure to work with Environment values. So we're already preparing for it in here!\n",
        "workspace_name = os.environ.get('WORKSPACE', 'mlops-nathan')\n",
        "subscription_id = os.environ.get('SUBSCRIPTION_ID', '7c50f9c3-289b-4ae0-a075-08784b3b9042')\n",
        "resource_group = os.environ.get('RESOURCE_GROUP', 'mlops')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1683701623388
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Because we are running this in an interactive notebook; we can use the InteractiveBrowserCredential\n",
        "# This allows us to open a browser window and login there\n",
        "credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1683701624170
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class FeatureStoreOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class FeatureSetOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class FeatureStoreEntityOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        }
      ],
      "source": [
        "ml_client = MLClient(\n",
        "    credential, subscription_id, resource_group, workspace_name\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare a Virtual PC if needed\n",
        "\n",
        "If we need to get a CPU cluster, or a single-node machine, we can again create on using the SDK...\n",
        "\n",
        "But we can also just create one in the Portal and then fetch it from here, which might be the safest option to be cheaper.\n",
        "\n",
        "When you're configuring it in the Portal, select the \"STANDARD_A4M_V2\" one to have enough RAM, CPU Power and Storage to run the scripts. The cheapest one is not powerful enough ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1683701692502
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ComputeInstance({'state': 'Running', 'last_operation': {'operation_name': 'Create', 'operation_time': '2023-10-04T12:45:39.211Z', 'operation_status': 'Succeeded', 'operation_trigger': 'User'}, 'os_image_metadata': <azure.ai.ml.entities._compute._image_metadata.ImageMetadata object at 0x125b72e00>, 'services': [{'display_name': 'Jupyter', 'endpoint_uri': 'https://zinnige-naam.westeurope.instances.azureml.ms/tree/'}, {'display_name': 'Jupyter Lab', 'endpoint_uri': 'https://zinnige-naam.westeurope.instances.azureml.ms/lab'}], 'type': 'computeinstance', 'created_on': None, 'provisioning_state': 'Succeeded', 'provisioning_errors': None, 'name': 'zinnige-naam', 'description': None, 'tags': None, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/7c50f9c3-289b-4ae0-a075-08784b3b9042/resourceGroups/mlops/providers/Microsoft.MachineLearningServices/workspaces/mlops-nathan/computes/zinnige-naam', 'Resource__source_path': None, 'base_path': '/Users/mctxr/MLOps-Les3', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x125b729b0>, 'resource_id': None, 'location': 'westeurope', 'size': 'STANDARD_DS3_V2', 'ssh_public_access_enabled': False, 'create_on_behalf_of': None, 'network_settings': <azure.ai.ml.entities._compute.compute.NetworkSettings object at 0x125b72f80>, 'ssh_settings': <azure.ai.ml.entities._compute.compute_instance.ComputeInstanceSshSettings object at 0x125b73280>, 'schedules': None, 'identity': None, 'idle_time_before_shutdown': None, 'idle_time_before_shutdown_minutes': None, 'setup_scripts': None, 'enable_node_public_ip': True, 'custom_applications': None, 'subnet': None})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute Instances need to have a unique name across the region.\n",
        "# Here we create a unique name with current datetime\n",
        "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
        "import datetime\n",
        "\n",
        "ci_basic_name = \"basic-ci\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M\")\n",
        "ci_basic = ComputeInstance(name=ci_basic_name, size=\"STANDARD_DS3_v2\")\n",
        "ml_client.begin_create_or_update(ci_basic).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also need to setup the Environment to use for our Data Preparation scripts.\n",
        "For this one, I call it \"aml-Pillow\", because we are mostly going to use the \"Pillow\" library to do the image processing.\n",
        "\n",
        "It requires a \"components/dataprep/conda.yaml\" file, which I will show you where to find and copy just now. It's in the \"azureml-2.0-automation/components/dataprep\" directory, because it was later used in there, and not copied, just cut... Sorry!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1683701627246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment with name aml-Pillow is registered to workspace, the environment version is 4\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-Pillow\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Image Processing (with Pillow)\",\n",
        "    tags={\"Pillow\": \"10.0.1\"},\n",
        "    conda_file=os.path.join(\"components\", \"dataprep\", \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1683701627365
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1683556923402
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./components/dataprep/dataprep.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {data_prep_src_dir}/dataprep.py\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--output_data\", type=str, help=\"path to output data\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    print(\"input data:\", args.data)\n",
        "    print(\"output folder:\", args.output_data)\n",
        "\n",
        "    output_dir = args.output_data\n",
        "    size = (64, 64) # Later we can also pass this as a property\n",
        "\n",
        "\n",
        "    for file in glob(args.data + \"/*.jpg\"):\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(size)\n",
        "\n",
        "        # Save the resized image to the output directory\n",
        "        output_file = os.path.join(output_dir, os.path.basename(file))\n",
        "        img_resized.save(output_file)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1683704215484
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "# This registers a component with the name \"data_prep_image_resize\"\n",
        "# Which can then be used in the Pipeline editor of the Azure Portal\n",
        "data_prep_component = command(\n",
        "    name=\"data_prep_image_resize_live\",\n",
        "    display_name=\"Data preparation, Image Resizing\",\n",
        "    description=\"Reads a data asset of images and preprocesses them by resizing them to 64 to 64.\",\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_folder\"),\n",
        "    },\n",
        "    outputs={\n",
        "        \"output_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    # The source folder of the component\n",
        "    code=os.path.join(\"components\", \"dataprep\"),\n",
        "    command=\"\"\"python dataprep.py \\\n",
        "            --data ${{inputs.data}} \\\n",
        "            --output_data ${{outputs.output_data}} \\\n",
        "            \"\"\",\n",
        "    environment=f\"aml-Pillow@latest\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1683704292690
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading dataprep (0.0 MBs): 100%|██████████| 1251/1251 [00:00<00:00, 18661.11it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component data_prep_image_resize_live with Version 2023-10-04-13-38-39-3593095 is registered\n"
          ]
        }
      ],
      "source": [
        "# Now we register the component to the workspace\n",
        "data_prep_component = ml_client.create_or_update(data_prep_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_prep_component.name} with Version {data_prep_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that it's registered, it's possible to start using it in the Pipelines.\n",
        "\n",
        "Because it's fun to do it from the SDK, we can show you that. But first, check out the recording to see how it works in the Azure Portal too..\n",
        "\n",
        "As you might've noticed in the recording, the designer is OK for a bit, but we can't really customize everything in there... That's why we want to take it a step further and automate it from the SDK in here..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1683707979201
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1683709398166
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"zinnige-naam\",\n",
        "    description=\"Custom data_prep pipeline\",\n",
        ")\n",
        "def animal_images_preprocessing_pipeline(\n",
        "    input_version: str, # Currently we don't use these version numbers, but we will use them later on.\n",
        "    output_version: str,\n",
        "):\n",
        "    # using data_prep_function like a python call with its own inputs\n",
        "    # These are the animals with the version name as a second item in the tuple\n",
        "    animals = [\n",
        "        ('pandas', \"1\"),\n",
        "        ('cats', \"1\"),\n",
        "        ('dogs', \"1\")\n",
        "    ] # They are hardcoded in here, because we should give them from another component otherwise.\n",
        "    \n",
        "    jobs = {}\n",
        "    for animal in animals:\n",
        "\n",
        "        data_prep_job = data_prep_component(\n",
        "            data=Input(\n",
        "                type=\"uri_folder\",\n",
        "                path=f\"azureml:{animal[0]}:{animal[1]}\" \n",
        "            ),\n",
        "        )\n",
        "        \n",
        "        output_name = animal[0] + \"_resized\"\n",
        "        output_path = \"azureml://subscriptions/7c50f9c3-289b-4ae0-a075-08784b3b9042/resourcegroups/mlops/workspaces/mlops-nathan/datastores/workspaceblobstore/paths/processed_animals/\" + animal[0]\n",
        "\n",
        "        data_prep_job.outputs.output_data = Output(\n",
        "            type=\"uri_folder\",\n",
        "            path=output_path,\n",
        "            name=output_name,\n",
        "            mode=\"rw_mount\"\n",
        "        )\n",
        "\n",
        "        jobs[animal[0]] = data_prep_job\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        k: v.outputs.output_data for k,v in jobs.items()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1683709400871
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "pipeline = animal_images_preprocessing_pipeline()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By executing the cell below, you're scripting something to make the Data Prep Pipeline run. It will use the \"dataprep.py\" script, which is located in the \"components/dataprep\" directory.\n",
        "\n",
        "It opened up your browser where you can see three different parallell runs. They will all take one of the datasets, and process it one by one, then upload it to the Datastore under the \"dogs_resized\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1683709441303
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import webbrowser\n",
        "\n",
        "# submit the pipeline job\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"image_preprocessing_pipeline\",\n",
        ")\n",
        "# open the pipeline in web browser\n",
        "webbrowser.open(pipeline_job.studio_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train test split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that they are all resized in the cloud, we can try to split them up into a train and test set as well.\n",
        "\n",
        "We will repeat the steps:\n",
        "- Create the Component script\n",
        "- Register the Component in Azure\n",
        "- Use the Component in a Pipeline\n",
        "- Run the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./components/dataprep/traintestsplit.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {data_prep_src_dir}/traintestsplit.py\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "from glob import glob\n",
        "import math\n",
        "import random\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    SEED = 42\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--datasets\", type=str, nargs=\"+\", help=\"All the datasets to combine\")\n",
        "    parser.add_argument(\"--training_data_output\", type=str, help=\"path to training output data\")\n",
        "    parser.add_argument(\"--testing_data_output\", type=str, help=\"path to testing output data\")\n",
        "    parser.add_argument(\"--split_size\", type=int, help=\"Percentage to use as Testing data\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    print(\"input data:\", args.datasets)\n",
        "    print(\"Training folder:\", args.training_data_output)\n",
        "    print(\"Testing folder:\", args.testing_data_output)\n",
        "    print(\"Split size:\", args.split_size)\n",
        "\n",
        "    train_test_split_factor = args.split_size / 100 # Alias\n",
        "    datasets = args.datasets\n",
        "\n",
        "    training_datapaths = []\n",
        "    testing_datapaths = []\n",
        "\n",
        "\n",
        "    for dataset in datasets:\n",
        "        animal_images = glob(dataset + \"/*.jpg\")\n",
        "        print(f\"Found {len(animal_images)} images for {dataset}\")\n",
        "\n",
        "        ## Concatenate the names for the animal_name and the img_path. Don't put a / between, because the img_path already contains that\n",
        "        ## animal_images = [(default_datastore, f'processed_animals/{animal_name}{img_path}') for img_path in animal_images] # Make sure the paths are actual DataPaths\n",
        "    \n",
        "        random.seed(SEED) # Use the same random seed as I use and defined in the earlier cells\n",
        "        random.shuffle(animal_images) # Shuffle the data so it's randomized\n",
        "\n",
        "        ## Testing images\n",
        "        amount_of_test_images = math.ceil(len(animal_images) * train_test_split_factor) # Get a small percentage of testing images\n",
        "\n",
        "        animal_test_images = animal_images[:amount_of_test_images]\n",
        "        animal_training_images = animal_images[amount_of_test_images:]\n",
        "\n",
        "        # Add them all to the other ones\n",
        "        testing_datapaths.extend(animal_test_images)\n",
        "        training_datapaths.extend(animal_training_images)\n",
        "\n",
        "        print(testing_datapaths[:5])\n",
        "\n",
        "        # Write the data to the output\n",
        "        for img in animal_test_images:\n",
        "            # Open the img, which is a string filepath, then save it to the args.testing_data_output directory\n",
        "            with open(img, \"rb\") as f:\n",
        "                with open(os.path.join(args.testing_data_output, os.path.basename(img)), \"wb\") as f2:\n",
        "                    f2.write(f.read())\n",
        "\n",
        "        for img in animal_training_images:\n",
        "            # Open the img, which is a string filepath, then save it to the args.testing_data_output directory\n",
        "            with open(img, \"rb\") as f:\n",
        "                with open(os.path.join(args.training_data_output, os.path.basename(img)), \"wb\") as f2:\n",
        "                    f2.write(f.read())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "data_split_component = command(\n",
        "    name=\"data_split\",\n",
        "    display_name=\"Data Splitting to Train and Test\",\n",
        "    description=\"Reads a data asset of images and combines them into a training and testing dataset\",\n",
        "    # We want to give the datasets as a dynamic input ...\n",
        "   inputs={\n",
        "        \"animal_1\": Input(type=\"uri_folder\"),\n",
        "        \"animal_2\": Input(type=\"uri_folder\"),\n",
        "        \"animal_3\": Input(type=\"uri_folder\"),\n",
        "        \"train_test_split_factor\": Input(type=\"number\"), # The percentage of the data to use as testing data, always a positive value\n",
        "    },\n",
        "    # ... and take the outputs as a dynamic output to override the training and testset locations.\n",
        "    outputs={\n",
        "        \"training_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "        \"testing_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    # The source folder of the component\n",
        "    code=os.path.join(\"components\", \"dataprep\"),\n",
        "    command=\"\"\"python traintestsplit.py \\\n",
        "            --datasets ${{inputs.animal_1}} ${{inputs.animal_2}} ${{inputs.animal_3}} \\\n",
        "            --split_size ${{inputs.train_test_split_factor}} \\\n",
        "            --training_data ${{outputs.training_data}} \\\n",
        "            --testing_data ${{outputs.testing_data}} \\\n",
        "            \"\"\",\n",
        "    environment=f\"aml-Pillow@latest\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading dataprep (0.0 MBs): 100%|██████████| 4155/4155 [00:00<00:00, 48507.49it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component data_split with Version 2023-10-04-14-12-52-9998659 is registered\n"
          ]
        }
      ],
      "source": [
        "# Now we register the component to the workspace\n",
        "data_split_component = ml_client.create_or_update(data_split_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_split_component.name} with Version {data_split_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"zinnige-naam\",\n",
        "    description=\"Custom data_prep pipeline\",\n",
        ")\n",
        "def animal_images_traintest_split_pipeline(\n",
        "    train_test_split: int, # Currently we don't use these version numbers, but we will use them later on.\n",
        "    animal_1: Input,\n",
        "    animal_2: Input,\n",
        "    animal_3: Input,\n",
        "):\n",
        "    # using data_prep_function like a python call with its own inputs\n",
        "    # These are the animals with the version name as a second item in the tuple\n",
        "\n",
        "    # Combining arguments starting with \"animals_\" into a dictionary\n",
        "    animals_args = {k: v for k, v in locals().items() if k.startswith(\"animals_\")}\n",
        "\n",
        "    # Create a component instance by calling the component factory\n",
        "    data_split_job = data_split_component(\n",
        "            animal_1=animal_1,\n",
        "            animal_2=animal_2,\n",
        "            animal_3=animal_3,\n",
        "            train_test_split_factor=train_test_split\n",
        "        )\n",
        "    \n",
        "    # Override the training data output and testing data output to a file named \"trainingdata\" and \"testingdata\n",
        "    data_split_job.outputs.training_data = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"training_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "    data_split_job.outputs.testing_data = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"testing_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"training_data\": data_split_job.outputs.training_data,\n",
        "        \"testing_data\": data_split_job.outputs.testing_data\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'animal_1': {'type': 'uri_folder', 'path': 'azureml:pandas_resized:1'}, 'animal_2': {'type': 'uri_folder', 'path': 'azureml:cats_resized:1'}, 'animal_3': {'type': 'uri_folder', 'path': 'azureml:dogs_resized:1'}}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "version = \"1\" # We can choose which version of the resized_pandas it will use\n",
        "animals = [\"pandas\", \"cats\", \"dogs\"]\n",
        "\n",
        "# Apparently, we made a small mistake in the naming conventions, but we will ignore that for now, we can fix it later...\n",
        "animals_datasets = {\n",
        "    f\"animal_{i+1}\": Input(type=\"uri_folder\", path=f\"azureml:{animal}_resized:{version}\")\n",
        "    for i, animal in enumerate(animals)\n",
        "}\n",
        "\n",
        "print(animals_datasets)\n",
        "\n",
        "train_test_pipeline = animal_images_traintest_split_pipeline(\n",
        "    **animals_datasets,\n",
        "    train_test_split=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import webbrowser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# submit the pipeline job\n",
        "train_test_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    train_test_pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"image_preprocessing_pipeline\",\n",
        ")\n",
        "# open the pipeline in web browser\n",
        "webbrowser.open(train_test_pipeline_job.studio_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check out how the pipeline looks now, we only take the \"resized\" parts, not the rest of the components, which already happened before. Later on, we will combine them of course!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will quickly go over the following steps, because they are basically the same all over again.\n",
        "- Create a component script\n",
        "- Register the component in Azure\n",
        "- Register an Environment if needed\n",
        "- Start training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment with name aml-Tensorflow-Pillow is registered to workspace, the environment version is 2\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-Tensorflow-Pillow\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for AI Training (with Pillow)\",\n",
        "    tags={\"Pillow\": \"10.0.1\", \"Tensorflow\": \"2.4.1\"},\n",
        "    conda_file=os.path.join(\"components\", \"training\", \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "training_component = command(\n",
        "    name=\"training\",\n",
        "    display_name=\"Training an AI model\",\n",
        "    description=\"Trains an AI model by inputting a lot of training and testing data.\",\n",
        "    inputs={\n",
        "        \"training_folder\": Input(type=\"uri_folder\"),\n",
        "        \"testing_folder\": Input(type=\"uri_folder\"),\n",
        "        \"epochs\": Input(type=\"number\") # The percentage of the data to use as testing data, always a positive value\n",
        "    },\n",
        "    outputs={\n",
        "        \"output_folder\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    # The source folder of the component\n",
        "    code=os.path.join(\"components\", \"training\"),\n",
        "    command=\"\"\"python train.py \\\n",
        "            --training_folder ${{inputs.training_folder}} \\\n",
        "            --testing_folder ${{inputs.testing_folder}} \\\n",
        "            --output_folder ${{outputs.output_folder}} \\\n",
        "            --epochs ${{inputs.epochs}} \\\n",
        "            \"\"\",\n",
        "    environment=f\"aml-Tensorflow-Pillow@latest\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component training with Version 2023-10-04-14-29-11-9827465 is registered\n"
          ]
        }
      ],
      "source": [
        "# Now we register the component to the workspace\n",
        "training_component = ml_client.create_or_update(training_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {training_component.name} with Version {training_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"zinnige-naam\",\n",
        "    description=\"Custom Animals Training pipeline\",\n",
        ")\n",
        "def animals_training_pipeline(\n",
        "    training_folder: Input, # Currently we don't use these version numbers, but we will use them later on.\n",
        "    testing_folder: Input,\n",
        "    epochs: int,\n",
        "):\n",
        "\n",
        "    training_job = training_component(\n",
        "        training_folder=training_folder,\n",
        "        testing_folder=testing_folder,\n",
        "        epochs=epochs\n",
        "    )\n",
        "    \n",
        "    # Let Azure decide a unique place everytime\n",
        "    training_job.outputs.output_folder = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"output_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"output_data\": training_job.outputs.output_folder,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "\n",
        "# Woops, make sure to use the correct version number here!\n",
        "training_pipeline = animals_training_pipeline(\n",
        "    # Change these versions if you want to override the choices\n",
        "    training_folder=Input(type=\"uri_folder\", path=f\"azureml:training_data:4\"),\n",
        "    testing_folder=Input(type=\"uri_folder\", path=f\"azureml:testing_data:14\"),\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import webbrowser\n",
        "# submit the pipeline job\n",
        "training_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    training_pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"training_pipeline\",\n",
        ")\n",
        "# open the pipeline in web browser\n",
        "webbrowser.open(training_pipeline_job.studio_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This pipeline ends here, we will not be chaining everything together yet, we will do that in the next Stage, where we will execute things from the CLI."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "mlops",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1489b69aef9188e253991a72f2c1dcab719183ba23071189a69ddf1bcdf6e734"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
